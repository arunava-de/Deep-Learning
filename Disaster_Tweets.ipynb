{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sporting-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "identified-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/nlp-getting-started/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "above-suicide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "worthy-sound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-honduras",
   "metadata": {},
   "source": [
    "## Looking at number of words in each body of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "electrical-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "wlens = df.text.apply(lambda x: len(word_tokenize(x)))\n",
    "df['text_lens'] = wlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "engaging-elder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_lens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  text_lens  \n",
       "0       1         14  \n",
       "1       1          8  \n",
       "2       1         24  \n",
       "3       1          9  \n",
       "4       1         18  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "educational-lincoln",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f80c02a2940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.countplot(x='text_lens', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dirty-credits",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f81151b0908>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['char_lens'] = df.text.apply(lambda x: len(x))\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.countplot(x='char_lens', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "overhead-intro",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>text_lens</th>\n",
       "      <th>char_lens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7613.00000</td>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5441.934848</td>\n",
       "      <td>0.42966</td>\n",
       "      <td>18.916590</td>\n",
       "      <td>101.037436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3137.116090</td>\n",
       "      <td>0.49506</td>\n",
       "      <td>6.871924</td>\n",
       "      <td>33.781325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2734.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5408.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8146.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>133.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10873.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>157.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      target    text_lens    char_lens\n",
       "count   7613.000000  7613.00000  7613.000000  7613.000000\n",
       "mean    5441.934848     0.42966    18.916590   101.037436\n",
       "std     3137.116090     0.49506     6.871924    33.781325\n",
       "min        1.000000     0.00000     1.000000     7.000000\n",
       "25%     2734.000000     0.00000    14.000000    78.000000\n",
       "50%     5408.000000     0.00000    19.000000   107.000000\n",
       "75%     8146.000000     1.00000    24.000000   133.000000\n",
       "max    10873.000000     1.00000    72.000000   157.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "narrow-basic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8115157d68>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.countplot(x='target', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-basketball",
   "metadata": {},
   "source": [
    "#### Remove hashtags, mentions and urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "reserved-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(temp):\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(\"#\",\"\", temp)\n",
    "    temp = re.sub(r\"http\\S+\", \"\", temp)\n",
    "    temp = re.sub(r\"www.\\S+\", \"\", temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "marine-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_cleaned'] = df['text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "tribal-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df.text_cleaned.values\n",
    "labels = df.target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-crown",
   "metadata": {},
   "source": [
    "## Fine-tuning BERT (too slow on CPU, ignore for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "intelligent-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "domestic-forum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  Our Deeds are the Reason of this earthquake May ALLAH Forgive us all\n",
      "Tokenized:  ['our', 'deeds', 'are', 'the', 'reason', 'of', 'this', 'earthquake', 'may', 'allah', 'forgive', 'us', 'all']\n",
      "Token IDs:  [2256, 15616, 2024, 1996, 3114, 1997, 2023, 8372, 2089, 16455, 9641, 2149, 2035]\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', df.text_cleaned.iloc[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(df.text_cleaned.iloc[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(df.text_cleaned.iloc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "covered-chemistry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  78\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for sent in df.text_cleaned:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "naval-membrane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Our Deeds are the Reason of this earthquake May ALLAH Forgive us all\n",
      "Token IDs: tensor([  101,  2256, 15616,  2024,  1996,  3114,  1997,  2023,  8372,  2089,\n",
      "        16455,  9641,  2149,  2035,   102,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 96,           # Pad & truncate all sentences.\n",
    "                        padding = 'max_length',\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-france",
   "metadata": {},
   "source": [
    "## Preparing train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "tropical-hungarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,851 training samples\n",
      "  762 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "brief-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "graduate-journalism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "optical-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ordered-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "quality-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "informational-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "familiar-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            outputs = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-jonathan",
   "metadata": {},
   "source": [
    "## Using a classifier on BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "provincial-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stone-sucking",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "compatible-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(text):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "    # Split the sentence into tokens.\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        hidden_states = outputs[2]\n",
    "        \n",
    "#     token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "#     token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "#     token_embeddings = token_embeddings.permute(1,0,2)\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    \n",
    "    return sentence_embedding.cpu().detach().numpy()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs = df['text_cleaned'].apply(get_bert_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sent_vecs.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-coverage",
   "metadata": {},
   "source": [
    "## Preparing train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.1, random_state=42)\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
