{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detailed-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/jigsaw-toxic-severity-rating/\"\n",
    "validation_data = pd.read_csv(data_path+\"validation_data.csv\")\n",
    "data = pd.read_csv(data_path+\"comments_to_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_freq_dict = dict(validation_data.worker.value_counts())\n",
    "workers = sorted(list(worker_freq_dict.keys()))\n",
    "worked = [worker_freq_dict[w] for w in workers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-guess",
   "metadata": {},
   "source": [
    "### Plotting worker productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(workers, worked, align='center', color='green')\n",
    "# plt.xticks(workers, worked)\n",
    "plt.title(\"Work distribution\")\n",
    "plt.xlabel(\"Worker ID\")\n",
    "plt.ylabel(\"Data points annotated\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "validation_data.worker.value_counts().plot(ax=ax, kind='hist', color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-escape",
   "metadata": {},
   "source": [
    "### Plotting length of each comment against type of comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_toxic_lens = validation_data.less_toxic.apply(lambda x: len(x.split()))\n",
    "more_toxic_lens = validation_data.more_toxic.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(10, 6))\n",
    " \n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "bp = ax.boxplot([less_toxic_lens, more_toxic_lens])\n",
    "\n",
    "ax.set_xticklabels(['less toxic', 'more toxic'])\n",
    "\n",
    "plt.title(\"Comment lengths box plot\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-klein",
   "metadata": {},
   "source": [
    "## Plotting few vectors in 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-requirement",
   "metadata": {},
   "source": [
    "Here we look at various embedding approaches and use UMAP to project them to 2D space and plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-jones",
   "metadata": {},
   "source": [
    "### Tf-idf plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=500)\n",
    "corpus = np.concatenate([validation_data.less_toxic.apply(lambda x: x.replace(\"\\n\", \"\")).values, \n",
    "                         validation_data.more_toxic.apply(lambda x: x.replace(\"\\n\", \"\")).values])\n",
    "tfidf_vecs = vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = validation_data.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_corpus_less = sampled_df.less_toxic.apply(lambda x: x.replace(\"\\n\", \"\")).values\n",
    "\n",
    "sampled_corpus_more = sampled_df.more_toxic.apply(lambda x: x.replace(\"\\n\", \"\")).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vecs_less = vectorizer.transform(sampled_corpus_less).toarray()\n",
    "tfidf_vecs_more = vectorizer.transform(sampled_corpus_more).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = umap.UMAP(n_components=2,\n",
    "                      n_neighbors=15,\n",
    "                      min_dist=0.3,\n",
    "                      metric='correlation').fit_transform(np.concatenate([tfidf_vecs_less, tfidf_vecs_more]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_less = embedding[:5000,0]\n",
    "y_less = embedding[:5000,1]\n",
    "x_more = embedding[5000:,0]\n",
    "y_more = embedding[5000:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter(x_less, y_less, color='green', alpha=0.5, label='less toxic')\n",
    "ax1.scatter(x_more, y_more, color='red', alpha=0.5, label='more toxic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-reading",
   "metadata": {},
   "source": [
    "We can see that both overlap quite a bit. We might need to move over to better embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-roman",
   "metadata": {},
   "source": [
    "### BERT plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "intelligent-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "blank-wrapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "stone-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(text):\n",
    "    \n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "    # Split the sentence into tokens.\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    \n",
    "    # Truncating to 512 tokens\n",
    "    tokenized_text = tokenized_text[:512]\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        hidden_states = outputs[2]\n",
    "        \n",
    "#     token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "#     token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "#     token_embeddings = token_embeddings.permute(1,0,2)\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    \n",
    "    return sentence_embedding.cpu().detach().numpy()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "complimentary-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = \" \".join(text.split())\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'[0-9]', '', text)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = validation_data.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['less_toxic_cleaned'] = sampled_df['less_toxic'].progress_apply(clean)\n",
    "sampled_df['more_toxic_cleaned'] = sampled_df['more_toxic'].progress_apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['less_toxic_vecs'] = sampled_df['less_toxic_cleaned'].progress_apply(get_bert_embedding)\n",
    "sampled_df['more_toxic_vecs'] = sampled_df['more_toxic_cleaned'].progress_apply(get_bert_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(sampled_df.less_toxic_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = umap.UMAP(n_components=2,\n",
    "                      n_neighbors=15,\n",
    "                      min_dist=0.3,\n",
    "                      metric='correlation').fit_transform(np.concatenate([list(sampled_df.less_toxic_vecs), \n",
    "                                                                          list(sampled_df.more_toxic_vecs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_less = embedding[:500,0]\n",
    "y_less = embedding[:500,1]\n",
    "x_more = embedding[500:,0]\n",
    "y_more = embedding[500:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter(x_less, y_less, color='cyan', alpha=0.5, label='less toxic')\n",
    "ax1.scatter(x_more, y_more, color='pink', alpha=0.5, label='more toxic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-austin",
   "metadata": {},
   "source": [
    "Too much overlap of BERT vectors as well. Seems unlikely that a classifier can do much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-evans",
   "metadata": {},
   "source": [
    "## Loading data from classification challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "romantic-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_classification_test = pd.read_csv(\"./data/jigsaw-toxic-comment-classification-challenge/test.csv\")\n",
    "toxic_classification_test_labels = pd.read_csv(\"./data/jigsaw-toxic-comment-classification-challenge/test_labels.csv\")\n",
    "toxic_classification_train = pd.read_csv(\"./data/jigsaw-toxic-comment-classification-challenge/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7766055a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12     -1            -1       -1      -1      -1   \n",
       "\n",
       "   identity_hate  \n",
       "0             -1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_classification_test_labels.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c93a57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(toxic_classification_test, toxic_classification_test_labels, how='left', on='id')\n",
    "df = pd.concat([toxic_classification_train, df_test])\n",
    "\n",
    "df['toxicity'] = (df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) > 0 ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32d7edb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    222860\n",
       "1       689\n",
       "Name: threat, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.threat.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efcdcbf",
   "metadata": {},
   "source": [
    "### Removing -1 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9578ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['toxic']!=-1) & (df['severe_toxic']!=-1) & (df['obscene']!=-1) & (df['threat']!=-1) & (df['insult']!=-1) & (df['identity_hate']!=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ca77f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223549, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e49017",
   "metadata": {},
   "source": [
    "### We add all label values to get idea of degree of severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c7dd59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['toxicity'] = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ead244",
   "metadata": {},
   "source": [
    "## Visualizing the comments in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85c8db63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1245/1245 [06:51<00:00,  3.02it/s]\n"
     ]
    }
   ],
   "source": [
    "sampled_df = df.groupby('toxicity', group_keys=False).apply(lambda x: x.sample(min(len(x), 200)))\n",
    "bert_vecs = sampled_df.comment_text.apply(clean).progress_apply(get_bert_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc855b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    200\n",
       "4    200\n",
       "3    200\n",
       "2    200\n",
       "1    200\n",
       "0    200\n",
       "6     45\n",
       "Name: toxicity, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.toxicity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fdef730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = umap.UMAP(n_components=2,\n",
    "                      n_neighbors=15,\n",
    "                      min_dist=0.1,\n",
    "                      metric='euclidean').fit_transform(list(bert_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0dd7a76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = embedding[:,0]\n",
    "y = embedding[:,1]\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca926f1",
   "metadata": {},
   "source": [
    "## Classifier fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddba0de",
   "metadata": {},
   "source": [
    "Idea is to fit a classifier to predict from 0 to 5, then use the predicted labels along with probability to rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a716973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  toxicity  \n",
       "0             0        0       0       0              0         0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44eeb22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
